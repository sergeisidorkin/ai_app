# ai_app/docops_queue/views.py
import json

from datetime import timedelta
from urllib.parse import urlparse, urlunparse, unquote, quote
from uuid import UUID, uuid4

from django.shortcuts import get_object_or_404
from django.conf import settings
from django.db import transaction
from django.db.models import Count
from django.http import JsonResponse, HttpResponseBadRequest
from django.utils import timezone
from django.views.decorators.http import require_POST, require_GET
from django.views.decorators.csrf import csrf_exempt

from docops_queue.models import Job
from docops_queue.urlkeys import make_doc_key

from logs_app import utils as plog

def _parse_uuid(v):
    try:
        return UUID(str(v))
    except Exception:
        return None

def _resolve_trace(request, body: dict | None, payload: dict | None) -> UUID:
    """
    –ï–¥–∏–Ω–∞—è —Ç–æ—á–∫–∞: –±–µ—Ä—ë–º trace –∏–∑ body/payload/–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤; –µ—Å–ª–∏ –Ω–µ—Ç/–Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π ‚Äî –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º.
    –ü–æ—Ä—è–¥–æ–∫:
      1) body.traceId
      2) payload.meta.trace_id
      3) payload.traceId
      4) X-Trace-Id / X-Request-Id –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
      5) uuid4()
    """
    candidate = (
        (body or {}).get("traceId")
        or ((payload or {}).get("meta") or {}).get("trace_id")
        or (payload or {}).get("traceId")
        or (getattr(request, "headers", {}) or {}).get("X-Trace-Id")
        or (getattr(request, "headers", {}) or {}).get("X-Request-Id")
        or ""
    )
    return _parse_uuid(candidate) or uuid4()

def _trace_from_payload_or_request(body: dict, payload: dict) -> str:
    # –ø—Ä–æ–±—É–µ–º –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å body.traceId (–µ—Å–ª–∏ –±—É–¥–µ—Ç–µ —Å–ª–∞—Ç—å),
    # –∑–∞—Ç–µ–º payload.meta.trace_id / payload.traceId
    return (
        (body or {}).get('traceId') or
        ((payload or {}).get('meta') or {}).get('trace_id') or
        (payload or {}).get('traceId') or
        ''
    )

def _payload_anchor_text(payload: dict) -> str:
    try:
        a = (payload or {}).get("anchor") or {}
        t = (a.get("text") or "").strip()
        return t
    except Exception:
        return ""

def _url_variants(u: str) -> list[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–±–æ—Ä –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ URL:
    - –∫–∞–∫ –ø—Ä–∏—à—ë–ª;
    - unquote (–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å %20 -> –ø—Ä–æ–±–µ–ª);
    - re-quote (–æ–±—Ä–∞—Ç–Ω–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã –∫–∞–∫ %20).
    –ü–ª—é—Å –ø—Ä–æ–≥–æ–Ω —á–µ—Ä–µ–∑ _normalize_url.
    """
    raw = (u or "").strip()
    out = set()
    def _norm(x: str) -> str:
        return _normalize_url(x)

    try:
        out.add(_norm(raw))
        uq = unquote(raw)
        out.add(_norm(uq))
        rq = quote(uq, safe=":/@%._-+=")
        out.add(_norm(rq))
    except Exception:
        pass
    # –≤—ã–∫–∏–Ω–µ–º –ø—É—Å—Ç—ã–µ
    return [x for x in out if x]

def _normalize_url(u: str) -> str:
    # —É–±–∏—Ä–∞–µ–º query/fragment, —Ç—Ä–∏–º–∏–º —Å–ª–µ—à –≤ –∫–æ–Ω—Ü–µ
    try:
        p = urlparse((u or "").strip())
        p = p._replace(query="", fragment="")
        s = urlunparse(p)
        return s.rstrip("/")
    except Exception:
        return (u or "").strip().rstrip("/")

def _ms_word_link(web_url: str) -> str:
    return f"ms-word:ofe|u|{web_url}"

def _user_bucket(u: str) -> str:
    """
    –í–µ—Ä–Ω—ë—Ç "host/personal/<user>" –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ (–±–µ–∑ —Å–ª—ç—à–∞ –≤ –∫–æ–Ω—Ü–µ)
    –¥–ª—è –æ–±–æ–∏—Ö —Ñ–æ—Ä–º URL: –∏ –æ–±—ã—á–Ω–æ–π, –∏ '/:w:/g/...'.
    """
    try:
        from urllib.parse import urlparse, unquote
        import re
        p = urlparse((u or "").strip())
        host = (p.netloc or "").lower()
        path = unquote(p.path or "")
        path = re.sub(r"/+", "/", path).strip().rstrip("/").lower()

        # '/:w:/g/personal/<user>/...'
        m = re.match(r"^/:w:/(?:g|r)/(personal/[^/]+)/", path)
        if m:
            return f"{host}/{m.group(1)}"

        # '/personal/<user>/...'
        n = re.match(r"^/(personal/[^/]+)/", path)
        if n:
            return f"{host}/{n.group(1)}"
    except Exception:
        pass
    return ""

def _ops_to_blocks(payload: dict) -> list[dict]:
    if not payload:
        return []

    # 1) –∫–æ—Ä–æ—Ç–∫–∞—è —Ñ–æ—Ä–º–∞: {"kind": "...", "text": "..."} –∏–ª–∏ {"op": "..."}
    if isinstance(payload, dict) and ((payload.get("kind") or payload.get("op")) and not payload.get("ops")):
        kind = (payload.get("kind") or payload.get("op") or "").strip().lower()
        if kind:
            b = {"kind": kind}
            if "text" in payload:  b["text"]  = payload["text"]
            if "style" in payload: b["style"] = payload["style"]
            return [b]

    # 2) –æ–±—ã—á–Ω–∞—è —Ñ–æ—Ä–º–∞: {"ops":[{...}, {...}]}
    ops = list((payload or {}).get("ops") or [])
    blocks = []
    for op in ops:
        kind = (op.get("kind") or op.get("op") or "").strip().lower()
        if not kind:
            continue
        b = {"kind": kind}
        if "text" in op:  b["text"]  = op["text"]
        if "style" in op: b["style"] = op["style"]
        blocks.append(b)
    return blocks

def _extract_filename(u: str) -> str:
    try:
        from urllib.parse import urlparse, unquote
        name = unquote(urlparse((u or "").strip()).path).rstrip("/").split("/")[-1]
        return (name or "").lower()
    except Exception:
        return ""




def _payload_from_blocks(blocks: list[dict], anchor_text: str | None) -> dict:
    out = {"ops": []}
    for b in blocks or []:
        kind = (b.get("kind") or b.get("op") or "").strip().lower()
        if not kind:
            continue
        item = {"op": kind}
        if "text" in b:
            item["text"] = b["text"]
        if "style" in b:
            item["style"] = b["style"]
        out["ops"].append(item)
    if anchor_text:
        out["anchor"] = {"text": anchor_text}
    return out

@csrf_exempt
@require_POST
def enqueue_from_pipeline(request):
    """
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ –ø–∞–π–ø–ª–∞–π–Ω–∞ '–°–æ–∑–¥–∞—Ç—å' –ø–æ—Å–ª–µ —Å–±–æ—Ä–∫–∏ blocks.
    –ñ–¥—ë—Ç JSON:
      {
        "doc": { "webUrl": "...", "url": "...", "shareUrl": "..." },
        "blocks": [...],             # docops blocks
        "target": {"marker": "..."}  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
        "priority": 10               # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
      }
    """
    try:
        data = json.loads(request.body.decode("utf-8"))
    except Exception as e:
        return HttpResponseBadRequest(f"bad json: {e}")

    doc = data.get("doc") or {}
    # –±–µ—Ä—ë–º –ª—é–±–æ–π –≤–∞–ª–∏–¥–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ —Å—Å—ã–ª–∫–∏ –Ω–∞ –¢–ï–ö–£–©–ò–ô –¥–æ–∫—É–º–µ–Ω—Ç
    raw_url = doc.get("webUrl") or doc.get("url") or doc.get("shareUrl") or ""
    doc_url = _normalize_url(raw_url)
    if not doc_url:
        return HttpResponseBadRequest("doc.webUrl/url/shareUrl required")

    blocks = data.get("blocks") or []
    marker = ((data.get("target") or {}).get("marker") or "").strip()
    priority = int(data.get("priority") or 10)

    # –ø—Ä–∏–≤–æ–¥–∏–º –∫ payload, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º—É —Å /api/docs/next
    payload = _payload_from_blocks(blocks, marker)
    trace_uuid = _resolve_trace(request, data, payload)

    j = Job.objects.create(
        doc_url=doc_url,
        payload=payload,
        priority=priority,
        trace_id=trace_uuid,
    )
    plog.info(
        None,
        phase="queue",
        event="enqueue",
        job_id=j.id,
        doc_url=j.doc_url,
        message="Enqueued from pipeline",
        trace_id=j.trace_id,
        data={"ops": len((payload or {}).get("ops") or []),
              "has_anchor": bool(marker)}
    )
    return JsonResponse({"ok": True, "jobId": str(j.id)})

@csrf_exempt
@require_POST
def enqueue(request):
    """
    –¢–ï–°–¢–û–í–´–ô endpoint: –ø–æ–ª–æ–∂–∏—Ç—å job –≤ –æ—á–µ—Ä–µ–¥—å.
    body: { "docUrl": "...", "payload": {...}, "priority": 10 }
    """
    try:
        data = json.loads(request.body.decode("utf-8"))
    except Exception as e:
        return HttpResponseBadRequest(f"bad json: {e}")

    doc_url = _normalize_url(data.get("docUrl") or "")
    payload_in = data.get("payload", None)  # ‚Üê –±–µ—Ä—ë–º –∫–∞–∫ –µ—Å—Ç—å, –±–µ–∑ or {}
    trace_uuid = _resolve_trace(request, data, payload_in)
    job_obj = data.get("job")
    ops_arr = data.get("ops")

    if payload_in is None:
        if isinstance(job_obj, dict):
            payload = {"ops": list(job_obj.get("ops") or [])}
            a = (job_obj.get("anchor") or {})
            if isinstance(a, dict) and isinstance(a.get("text"), str) and a["text"].strip():
                payload["anchor"] = {"text": a["text"].strip()}
        elif isinstance(ops_arr, list):
            payload = {"ops": list(ops_arr)}
        else:
            payload = {}
    else:
        payload = payload_in

    priority = int(data.get("priority") or 10)

    if not doc_url:
        return HttpResponseBadRequest("docUrl required")

    j = Job.objects.create(
        doc_url=doc_url,
        payload=payload,
        priority=priority,
        trace_id=trace_uuid,
    )

    anchor_text = _payload_anchor_text(payload)
    plog.info(
        None, phase="queue", event="enqueue", message="Job enqueued",
        job_id=j.id, doc_url=j.doc_url, anchor_text=anchor_text,
        trace_id=j.trace_id,
        data={
            "priority": j.priority,
            "ops": len((payload or {}).get("ops") or []),
            "has_anchor": bool(anchor_text),
        },
    )
    return JsonResponse({"ok": True, "jobId": str(j.id)})

@csrf_exempt
@require_POST
def agent_pull(request, agent_id: str):
    """
    –ê–≥–µ–Ω—Ç —Ç—è–Ω–µ—Ç —Å–ª–µ–¥—É—é—â–µ–µ –∑–∞–¥–∞–Ω–∏–µ.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
      1) —É–∂–µ ASSIGNED –Ω–∞ —ç—Ç–æ–≥–æ –∂–µ –∞–≥–µ–Ω—Ç–∞ (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å);
      2) –ø—Ä–æ—Ç—É—Ö—à–∏–µ ASSIGNED (reclaim) ‚Üí –ø–µ—Ä–µ–ø—Ä–∏–≤—è–∑—ã–≤–∞–µ–º –∫ —ç—Ç–æ–º—É –∞–≥–µ–Ω—Ç—É;
      3) –æ–±—ã—á–Ω—ã–µ QUEUED ‚Üí –Ω–∞–∑–Ω–∞—á–∞–µ–º –∏ –æ—Ç–¥–∞—ë–º.
    """
    now = timezone.now()
    RECLAIM_AFTER = timedelta(minutes=5)

    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—á–µ—Ä–µ–¥–∏ –ø–µ—Ä–µ–¥ –ø—Ä–∏–Ω—è—Ç–∏–µ–º —Ä–µ—à–µ–Ω–∏—è
    stats = list(Job.objects.values("status").annotate(c=Count("id")).order_by())
    top_q = Job.objects.filter(status=Job.Status.QUEUED).order_by("-priority", "created_at").values_list("id",
                                                                                                         flat=True).first()
    plog.debug(
        None, phase="agent", event="pull.in",
        message=f"agent={agent_id}",
        data={"stats": stats, "top_queued": str(top_q) if top_q else None}
    )

    def _job_payload(j: Job) -> JsonResponse:
        # ¬´–ü–æ–¥–ª–µ—á–∏–≤–∞–µ–º¬ª —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞–Ω–∏—è –±–µ–∑ trace_id
        if not j.trace_id:
            j.trace_id = uuid4()
            # updated_at –æ–±—ã—á–Ω–æ auto_now; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –¥–æ–±–∞–≤—å—Ç–µ –≤ —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π
            j.save(update_fields=["trace_id"])
        web_url = j.doc_url
        return JsonResponse({
            "ok": True,
            "job": {
                "id": str(j.id),
                "webUrl": web_url,
                "msLink": _ms_word_link(web_url),
                "traceId": (str(j.trace_id) if j.trace_id else None),  # ‚Üê –¥–æ–±–∞–≤–∏—Ç—å
            }
        })

    # 1) –£–∂–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω—ã–µ –Ω–∞ –≠–¢–û–ì–û –∞–≥–µ–Ω—Ç–∞ (ASSIGNED –∏–ª–∏ IN_PROGRESS)
    j = Job.objects.filter(
        assigned_agent=agent_id,
        status__in=[Job.Status.ASSIGNED, Job.Status.IN_PROGRESS]
    ).order_by("-priority", "created_at").first()
    if j:
        plog.info(None, phase="agent", event="pull.assigned_existing",
                  message="Return already assigned to this agent",
                  job_id=j.id, doc_url=j.doc_url,
                  trace_id=j.trace_id,
                  data={"agent_id": agent_id, "status": j.status})
        return _job_payload(j)

    # 2) –†–µ-–∫–ª–µ–π–º –ø—Ä–æ—Ç—É—Ö—à–∏—Ö ASSIGNED (–∫—Ç–æ-—Ç–æ —Å–¥–µ–ª–∞–ª /pull –∏ –∏—Å—á–µ–∑)
    j = Job.objects.filter(
            status=Job.Status.ASSIGNED,
            started_at__lt=now - RECLAIM_AFTER
        ).order_by("started_at").first()
    if j:
        old_agent = j.assigned_agent
        j.assigned_agent = agent_id
        j.save(update_fields=["assigned_agent", "updated_at"])
        plog.warn(None, phase="agent", event="pull.reclaim",
                  message=f"Reclaim ASSIGNED job from '{old_agent}'",
                  job_id=j.id, doc_url=j.doc_url,
                  trace_id=j.trace_id,
                  data={"agent_id": agent_id})
        return _job_payload(j)

    # 3) –û–±—ã—á–Ω—ã–µ QUEUED
    j = Job.objects.filter(status=Job.Status.QUEUED) \
                   .order_by("-priority", "created_at").first()
    if not j:
        return JsonResponse({"ok": True, "job": None})

    j.status = Job.Status.ASSIGNED
    j.assigned_agent = agent_id
    j.started_at = now
    j.attempts += 1
    j.save(update_fields=["status", "assigned_agent", "started_at", "attempts", "updated_at"])

    plog.info(None, phase="agent", event="pull.assigned_new",
              message="Assigned QUEUED to agent",
              job_id=j.id, doc_url=j.doc_url,
              trace_id=j.trace_id,
              data={"agent_id": agent_id})
    return _job_payload(j)

@csrf_exempt
@require_POST
def docs_next(request):
    data = json.loads(request.body or "{}")
    url = (data.get("url") or "").strip()
    if not url:
        return JsonResponse({"ok": True, "job": None})

    key    = make_doc_key(url)
    bucket = _user_bucket(url)

    # 1) –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ QUEUED
    job = (Job.objects
           .filter(status=Job.Status.QUEUED, doc_key=key)
           .order_by("-priority", "created_at")
           .first())

    # 2) –¢–æ—á–Ω–æ–µ —Å—Ä–µ–¥–∏ ASSIGNED/IN_PROGRESS
    if job is None:
        job = (Job.objects
               .filter(status__in=[Job.Status.ASSIGNED, Job.Status.IN_PROGRESS], doc_key=key)
               .order_by("-priority", "created_at")
               .first())

    # 3) –§–æ–ª–±—ç–∫ –ø–æ user-bucket (—Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—ã URL –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)
    if job is None and bucket:
        job = (Job.objects
               .filter(status__in=[Job.Status.QUEUED, Job.Status.ASSIGNED, Job.Status.IN_PROGRESS],
                       doc_key__contains=bucket)
               .order_by("-priority", "created_at")
               .first())

    if not job:
        plog.debug(None, phase="docs", event="next.none")
        return JsonResponse({"ok": True, "job": None})

    # –ü–µ—Ä–µ–≤–æ–¥–∏–º QUEUED ‚Üí IN_PROGRESS (–∫–∞–∫ –±—ã–ª–æ)
    if job.status == Job.Status.QUEUED:
        job.status = Job.Status.IN_PROGRESS
        job.save(update_fields=["status", "updated_at"])

    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º trace_id (–∫–∞–∫ –±—ã–ª–æ)
    if not job.trace_id:
        job.trace_id = uuid4()
        job.save(update_fields=["trace_id"])

    payload = job.payload or {}

    # üîÅ NEW: –µ—Å–ª–∏ —É–∂–µ –ø–æ–ª–æ–∂–∏–ª–∏ –ì–û–¢–û–í–´–ô addin.block ‚Äî –æ—Ç–¥–∞–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
    if isinstance(payload, dict) and str(payload.get("type") or "").lower() == "addin.block":
        plog.info(None, phase="docs", event="next.found",
                  job_id=job.id, doc_url=job.doc_url, trace_id=job.trace_id,
                  message="addin.block passthrough")
        return JsonResponse({
            "ok": True,
            "job": {
                "id": str(job.id),
                "payload": payload,                 # ‚Üê —É–∂–µ {type:"addin.block",...}
                "traceId": str(job.trace_id),
            }
        })

    # ‚Üì‚Üì‚Üì –°–¢–ê–†–´–ô –ü–£–¢–¨ (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å): ops ‚Üí blocks + anchor ‚Üí target
    anchor_text = _payload_anchor_text(payload)
    blocks = (payload.get("blocks") or _ops_to_blocks(payload)) if isinstance(payload, dict) else []
    payload_out = {"blocks": blocks}
    if anchor_text:
        payload_out["target"] = {"marker": anchor_text}

    plog.info(None, phase="docs", event="next.found",
              job_id=job.id, doc_url=job.doc_url, trace_id=job.trace_id)

    return JsonResponse({
        "ok": True,
        "job": {
            "id": str(job.id),
            "payload": payload_out,
            "traceId": str(job.trace_id),
        }
    })

@csrf_exempt
@require_POST
def job_complete(request, job_id):
    try:
        data = json.loads(request.body.decode("utf-8"))
    except Exception as e:
        return HttpResponseBadRequest(f"bad json: {e}")

    ok = bool(data.get("ok"))
    message = (data.get("message") or "")[:2000]
    # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –º–µ—Ç—Ä–∏–∫–∏, —Å—á–µ—Ç—á–∏–∫–∏, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ç.–¥.

    try:
        j = Job.objects.get(id=job_id)
    except Job.DoesNotExist:
        return HttpResponseBadRequest("job not found")

    j.status = Job.Status.DONE if ok else Job.Status.FAILED
    j.last_error = "" if ok else (message or "failed")
    j.finished_at = timezone.now()
    j.save(update_fields=["status","last_error","finished_at","updated_at"])
    if ok:
        plog.info(None, phase="queue", event="complete.ok",
                  job_id=j.id, doc_url=j.doc_url,
                  trace_id=(str(j.trace_id) if j.trace_id else None), message=message or "")
    else:
        plog.error(None, phase="queue", event="complete.failed",
                   job_id=j.id, doc_url=j.doc_url, trace_id=(str(j.trace_id) if j.trace_id else None),
                   message=message or "failed")
    return JsonResponse({"ok": True})

@require_GET
def job_detail(request, job_id: UUID):
    j = get_object_or_404(Job, id=job_id)
    return JsonResponse({
        "id": str(j.id),
        "status": j.status,
        "priority": j.priority,
        "docUrl": j.doc_url,
        "payload": j.payload,
        "assignedAgent": j.assigned_agent,
        "attempts": j.attempts,
        "lastError": j.last_error,
        "createdAt": j.created_at.isoformat(),
        "updatedAt": j.updated_at.isoformat(),
        "startedAt": j.started_at.isoformat() if j.started_at else None,
        "finishedAt": j.finished_at.isoformat() if j.finished_at else None,
        "traceId": str(j.trace_id) if j.trace_id else None,
    })

@csrf_exempt
@require_POST
def reset_stale(request):
    mins = int((json.loads(request.body or b"{}") or {}).get("minutes", 5))
    n = timezone.now() - timedelta(minutes=mins)
    c = Job.objects.filter(status=Job.Status.ASSIGNED, started_at__lt=n) \
                   .update(status=Job.Status.QUEUED, assigned_agent="")
    plog.warn(None, phase="queue", event="reset_stale",
              message=f"Reset stale ASSIGNED ‚Üí QUEUED: {c}",
              data={"minutes": mins})
    return JsonResponse({"ok": True, "reset": c, "minutes": mins})